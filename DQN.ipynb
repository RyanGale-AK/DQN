{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "env = gym.make('Pong-v0').unwrapped\n",
    "\n",
    "# set up matplotlib to open viewing window\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "def get_screen():\n",
    "    # convert to channel,h,w dimensions\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    \n",
    "    # erase background\n",
    "    screen[screen == 72] = 0 \n",
    "    screen[screen == 74] = 0 \n",
    "    screen[screen == 144] = 0 \n",
    "    screen[screen != 0] = 213\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    \n",
    "    screen = torch.from_numpy(screen)\n",
    "    \n",
    "    # convert to batch,channel,h,w dimensions\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "env.reset()\n",
    "# run game for a bit to load the ball and opponent paddle\n",
    "for i in range(50):\n",
    "    env.step(0)\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 52, 40])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "gamma = 0.98\n",
    "buffer_limit = 50000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "store previous sequence-action pairs to decorrelate temporal locality\n",
    "transitions are composed of state, action, reward, next_state, and done_mask\n",
    "\"\"\"\n",
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "        \n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "            \n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "               torch.tensor(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, h, w = get_screen().shape\n",
    "\n",
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))\n",
    "    \n",
    "    # action is either random or max probability estimated by Qnet\n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs) # don't need if random action \n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0,1)\n",
    "        else:\n",
    "            return out.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory, optimizer):\n",
    "    for i in range(10):\n",
    "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
    "        \n",
    "        q_out = q(s)\n",
    "        # collect output from the chosen action dimension\n",
    "        q_a = q_out.gather(1,a) \n",
    "        \n",
    "        # most reward we get in next state s_prime\n",
    "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        # how much is our policy different from the true target \n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    env = gym.make('Pong-v0')\n",
    "    q = Qnet()\n",
    "    q_target = Qnet()\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    memory = ReplayBuffer()\n",
    "    \n",
    "    print_interval = 20\n",
    "    score = 0.0\n",
    "    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for episode in range(10):\n",
    "        # anneal 8% to 1% over training\n",
    "        epsilon = max(0.01, 0.08 - 0.01*(episode/200))\n",
    "        env.reset()\n",
    "        current_s = get_screen()\n",
    "        done = False\n",
    "        last_s = get_screen()\n",
    "        current_s = get_screen()\n",
    "        s = last_s - current_s\n",
    "        \n",
    "        while not done:\n",
    "            \n",
    "            \n",
    "            a = q.sample_action(s, epsilon)\n",
    "            # first variable would be s_prime but we have get_screen\n",
    "            _, r, done, info = env.step(a)\n",
    "            last_s = current_s\n",
    "            current_s = get_screen()\n",
    "            s_prime = last_s - current_s\n",
    "            \n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            memory.put((s,a,r/100.,s_prime,done_mask))\n",
    "            s = s_prime\n",
    "            \n",
    "            score += r\n",
    "            if done:\n",
    "                break\n",
    "        if memory.size()>2000:\n",
    "            train(q, q_target, memory, optimizer)\n",
    "        \n",
    "        if episode%print_interval==0 and episode!=0:\n",
    "            q_target.load_state_dict(q.state_dict())\n",
    "            print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
    "                episode, score/print_interval, memory.size(), epsilon*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 52, 40])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-a1af0163e5a0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mprint_interval\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0f8ead980c8b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(q, q_target, memory, optimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_prime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mq_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-46a7eaa89457>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mdone_mask_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdone_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_prime_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_mask_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
